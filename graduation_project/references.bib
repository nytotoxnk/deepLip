@article{PAWAR2024100084,
title = {Generating dynamic lip-syncing using target audio in a multimedia environment},
journal = {Natural Language Processing Journal},
volume = {8},
pages = {100084},
year = {2024},
issn = {2949-7191},
doi = {https://doi.org/10.1016/j.nlp.2024.100084},
url = {https://www.sciencedirect.com/science/article/pii/S2949719124000323},
author = {Diksha Pawar and Prashant Borde and Pravin Yannawar},
keywords = {AVSR, GAN, vVISWa dataset, LipChanger, LSTM},
abstract = {The presented research focuses on the challenging task of creating lip-sync facial videos that align with a specified target speech segment. A novel deep-learning model has been developed to produce precise synthetic lip movements corresponding to the speech extracted from an audio source. Consequently, there are instances where portions of the visual data may fall out of sync with the updated audio and this challenge is handled through, a novel strategy, leveraging insights from a robust lip-sync discriminator. Additionally, this study introduces fresh criteria and evaluation benchmarks for assessing lip synchronization in unconstrained videos. LipChanger demonstrates improved PSNR values, indicative of enhanced image quality. Furthermore, it exhibits highly accurate lip synthesis, as evidenced by lower LMD values and higher SSIM values. These outcomes suggest that the LipChanger approach holds significant potential for enhancing lip synchronization in talking face videos, resulting in more realistic lip movements. The proposed LipChanger model and its associated evaluation benchmarks show promise and could potentially contribute to advancements in lip-sync technology for unconstrained talking face videos.}
}
@inproceedings{Li_2021,
   title={A Novel Speech-Driven Lip-Sync Model with CNN and LSTM},
   url={http://dx.doi.org/10.1109/CISP-BMEI53629.2021.9624360},
   DOI={10.1109/cisp-bmei53629.2021.9624360},
   booktitle={2021 14th International Congress on Image and Signal Processing, BioMedical Engineering and Informatics (CISP-BMEI)},
   publisher={IEEE},
   author={Li, Xiaohong and Wang, Xiang and Wang, Kai and Lian, Shiguo},
   year={2021},
   month=oct, pages={1â€“6} }
@manual{google_api_docs,
  author = {Google Cloud},
  title = {Speech to Text API},
  url = {https://cloud.google.com/speech-to-text/v2/docs},
}

@techreport{game-lipsynch,
  author = {Jonathan Gratch, Arien Kock},
  institution = {University of Twente, Department of Computer Science, University of SOurthern California, Institute for Creative Technologies},
  title = {An Evaluation of Automatic Lip-syncing Methods for Game Environments},
  year = {2022}
}